bundle:
  name: dlt-pipeline-bundle

targets:
  development:
    workspace:
      # Use a placeholder string here
      host: "DATABRICKS_HOST_PLACEHOLDER"
    resources:
      pipelines:
        dlt_pipeline:
          name: "DLT Pipeline - Development"
          target: "development"
          libraries:
            - file:
                path: "dlt_pipeline.py"
          configuration:
            "spark.databricks.delta.schema.autoMerge.enabled": "true"
            "pipelines.trigger.interval": "0 0 * * * ?" # Daily at midnight
          channel: "preview"
          development: true
          continuous: false
          allow_duplicate_names: false

  production:
    workspace:
      # Same placeholder or a different one if you want separate hosts per target
      host: "DATABRICKS_HOST_PLACEHOLDER"
    resources:
      pipelines:
        dlt_pipeline:
          name: "DLT Pipeline - Production"
          target: "production"
          libraries:
            - file:
                path: "dlt_pipeline.py"
          configuration:
            "spark.databricks.delta.schema.autoMerge.enabled": "true"
            "pipelines.trigger.interval": "0 0 * * * ?" # Daily at midnight
          channel: "current"
          development: false
          continuous: false
          allow_duplicate_names: false
